langchain4j:
  open-ai:
    chat-model:
      base-url: https://api.openai.com/v1
      api-key: ${OPENAI_API_KEY}
      model-name: gpt-4
      log-requests: true
      log-responses: true
      # 超时配置（单位：毫秒）
      # 连接超时：30秒 = 30000毫秒
      # 读取超时：120秒 = 120000毫秒
      connect-timeout: 30000
      read-timeout: 120000
      timeout: 120000

#      通义千问 测试用
#      base-url: https://dashscope.aliyuncs.com/compatible-mode/v1
#      api-key: ${API_KEY_LLM_BAILIAN}
#      model-name: qwen-plus
#      log-requests: true
#      log-responses: true
    streaming-chat-model:
      base-url: https://dashscope.aliyuncs.com/compatible-mode/v1
      api-key: ${API_KEY_LLM_BAILIAN}
      model-name: qwen-plus
      log-requests: true
      log-responses: true

## 文件上传配置
#spring:
#  servlet:
#    multipart:
#      enabled: true
#      max-file-size: 10MB
#      max-request-size: 50MB
#      location: ${java.io.tmpdir}

#logging:
#  level:
#    dev.langchain4j: debug